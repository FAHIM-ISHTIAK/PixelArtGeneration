{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:19:19.480621Z","iopub.execute_input":"2026-02-21T05:19:19.480895Z","iopub.status.idle":"2026-02-21T05:19:24.017875Z","shell.execute_reply.started":"2026-02-21T05:19:19.480862Z","shell.execute_reply":"2026-02-21T05:19:24.017161Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nfrom datasets import load_dataset\nfrom PIL import Image\nfrom tqdm import tqdm\n\nTRAIN_DIR = \"/kaggle/working/plan_b_train_data\"\nTARGET_SIZE = 1024  # Upscale target for SSD-1B\nos.makedirs(TRAIN_DIR, exist_ok=True)\n\n# 1. Download directly from Hugging Face\nprint(\"Downloading pixel-art-nouns-2k from Hugging Face...\")\ndataset = load_dataset(\"jiovine/pixel-art-nouns-2k\", split=\"train\")\n\nmetadata = []\nprint(f\"Upscaling {len(dataset)} images using Nearest Neighbor...\")\n\nfor i, item in enumerate(tqdm(dataset)):\n    try:\n        # HF datasets automatically load images as PIL objects\n        img = item['image']\n        \n        # The text column in this specific dataset is usually 'text'\n        caption = item['text'] \n        \n        if img.mode != \"RGB\":\n            img = img.convert(\"RGB\")\n            \n        # 2. Crucial Step: Nearest Neighbor upscaling to keep pixels sharp\n        img_upscaled = img.resize((TARGET_SIZE, TARGET_SIZE), resample=Image.NEAREST)\n        \n        filename = f\"noun_{i}.png\"\n        img_upscaled.save(os.path.join(TRAIN_DIR, filename), \"PNG\")\n        \n        # Add your mandatory style trigger (optional but recommended)\n        full_caption = \"pixel art, 16-bit, sprite, \" + str(caption)\n        metadata.append({\"file_name\": filename, \"text\": full_caption})\n        \n    except Exception as e:\n        print(f\"Skipping image {i} due to error: {e}\")\n\n# 3. Save the JSONL file for the trainer\nwith open(os.path.join(TRAIN_DIR, \"metadata.jsonl\"), 'w') as f:\n    for entry in metadata:\n        f.write(json.dumps(entry) + \"\\n\")\n        \nprint(f\"Plan B Data Ready! Saved to {TRAIN_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:19:24.020263Z","iopub.execute_input":"2026-02-21T05:19:24.02099Z","iopub.status.idle":"2026-02-21T05:20:45.719457Z","shell.execute_reply.started":"2026-02-21T05:19:24.020951Z","shell.execute_reply":"2026-02-21T05:20:45.71877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# from PIL import Image\n# import os\n\n# # Path to your newly processed Plan B dataset\n# TRAIN_DIR = \"/kaggle/working/plan_b_train_data\"\n\n# # Grab the very first image we processed\n# sample_image_path = os.path.join(TRAIN_DIR, \"noun_0.png\")\n\n# if os.path.exists(sample_image_path):\n#     img = Image.open(sample_image_path)\n    \n#     # Display the image\n#     plt.figure(figsize=(8, 8))\n#     plt.imshow(img)\n#     plt.title(f\"Upscaled Resolution: {img.size[0]}x{img.size[1]} pixels\\n(Notice the crisp edges!)\", fontsize=14)\n#     plt.axis('off') # Hides the axis numbers for a cleaner look\n#     plt.show()\n# else:\n#     print(\"Image not found. Make sure the Plan B Data Prep cell has finished running completely!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:20:45.720402Z","iopub.execute_input":"2026-02-21T05:20:45.720811Z","iopub.status.idle":"2026-02-21T05:20:45.724536Z","shell.execute_reply.started":"2026-02-21T05:20:45.720779Z","shell.execute_reply":"2026-02-21T05:20:45.723776Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install the necessary libraries\n!pip install -U -q diffusers accelerate transformers peft bitsandbytes\n!pip install -q wandb # For metric identification and tracking\n\n# Download the official training script for SDXL/SSD-1B\n!wget https://raw.githubusercontent.com/huggingface/diffusers/main/examples/text_to_image/train_text_to_image_lora_sdxl.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:20:45.725277Z","iopub.execute_input":"2026-02-21T05:20:45.725871Z","iopub.status.idle":"2026-02-21T05:20:55.013015Z","shell.execute_reply.started":"2026-02-21T05:20:45.725839Z","shell.execute_reply":"2026-02-21T05:20:55.012347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Uninstall existing version to avoid conflicts\n!pip uninstall -y diffusers\n\n# 2. Install the latest \"dev\" version from source\n!pip install git+https://github.com/huggingface/diffusers\n\n# 3. Ensure other dependencies are up to date for SSD-1B\n!pip install -U -q accelerate transformers peft bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:20:55.014193Z","iopub.execute_input":"2026-02-21T05:20:55.014494Z","iopub.status.idle":"2026-02-21T05:21:17.002637Z","shell.execute_reply.started":"2026-02-21T05:20:55.014468Z","shell.execute_reply":"2026-02-21T05:21:17.001594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!accelerate launch --num_processes=1 train_text_to_image_lora_sdxl.py \\\n  --pretrained_model_name_or_path=\"segmind/SSD-1B\" \\\n  --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" \\\n  --train_data_dir=\"/kaggle/working/plan_b_train_data\" \\\n  --caption_column=\"text\" \\\n  --resolution=1024 \\\n  --mixed_precision=\"fp16\" \\\n  --train_batch_size=1 \\\n  --gradient_accumulation_steps=8 \\\n  --learning_rate=1e-4 \\\n  --rank=16 \\\n  --max_train_steps=1000 \\\n  --checkpointing_steps=100 \\\n  --validation_prompt=\"pixel art, 16-bit, sprite, an owl\" \\\n  --validation_epochs=1 \\\n  --num_validation_images=4 \\\n  --output_dir=\"/kaggle/working/court_of_owls_lora_plan_b\" \\\n  --seed=42 \\\n  --report_to=\"tensorboard\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T05:21:17.004108Z","iopub.execute_input":"2026-02-21T05:21:17.004458Z","iopub.status.idle":"2026-02-21T06:23:39.189959Z","shell.execute_reply.started":"2026-02-21T05:21:17.004422Z","shell.execute_reply":"2026-02-21T06:23:39.189023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom diffusers import DiffusionPipeline\nimport matplotlib.pyplot as plt\nimport os\n\n# Load the base model\npipe = DiffusionPipeline.from_pretrained(\n    \"segmind/SSD-1B\",\n    torch_dtype=torch.float16,\n    variant=\"fp16\"\n)\npipe.to(\"cuda\")\n\n# Load your trained LoRA weights\npipe.load_lora_weights(\"/kaggle/working/court_of_owls_lora_plan_b/pytorch_lora_weights.safetensors\")\n\n# Generate test images\nprompts = [\n\"a character with square black glasses, a hotdog-shaped head and a peachy-colored body on a warm background\"\n]\n\nimages = []\nfor prompt in prompts:\n    image = pipe(\n        prompt=prompt,\n        num_inference_steps=25,\n        guidance_scale=7.5,\n        generator=torch.Generator(\"cuda\").manual_seed(42)\n    ).images[0]\n    images.append(image)\n\n# Display results\nfig, axes = plt.subplots(1, 4, figsize=(20, 5))\nfor ax, img, prompt in zip(axes, images, prompts):\n    ax.imshow(img)\n    ax.set_title(prompt, fontsize=10)\n    ax.axis('off')\nplt.tight_layout()\n\n# Create output directory and save\nos.makedirs(\"/kaggle/working/output\", exist_ok=True)\nplt.savefig(\"/kaggle/working/output/validation_results.png\")\nplt.show()\n\nprint(\"Images saved to: /kaggle/working/output/validation_results.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T06:40:14.97367Z","iopub.execute_input":"2026-02-21T06:40:14.974432Z","iopub.status.idle":"2026-02-21T06:40:35.207114Z","shell.execute_reply.started":"2026-02-21T06:40:14.974399Z","shell.execute_reply":"2026-02-21T06:40:35.206419Z"}},"outputs":[],"execution_count":null}]}