{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-31T08:14:06.545141Z",
     "iopub.status.busy": "2026-01-31T08:14:06.544909Z",
     "iopub.status.idle": "2026-01-31T08:14:09.821219Z",
     "shell.execute_reply": "2026-01-31T08:14:09.820552Z",
     "shell.execute_reply.started": "2026-01-31T08:14:06.545116Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m--2026-01-31 08:14:09--  https://raw.githubusercontent.com/huggingface/diffusers/main/examples/text_to_image/train_text_to_image_lora_sdxl.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 56285 (55K) [text/plain]\n",
      "Saving to: ‘train_text_to_image_lora_sdxl.py.2’\n",
      "\n",
      "train_text_to_image 100%[===================>]  54.97K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2026-01-31 08:14:09 (4.63 MB/s) - ‘train_text_to_image_lora_sdxl.py.2’ saved [56285/56285]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install the necessary libraries\n",
    "!pip install -U -q diffusers accelerate transformers peft bitsandbytes\n",
    "!pip install -q wandb # For metric identification and tracking\n",
    "\n",
    "# Download the official training script for SDXL/SSD-1B\n",
    "!wget https://raw.githubusercontent.com/huggingface/diffusers/main/examples/text_to_image/train_text_to_image_lora_sdxl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:44:51.676199Z",
     "iopub.status.busy": "2026-01-31T06:44:51.675287Z",
     "iopub.status.idle": "2026-01-31T06:45:13.233696Z",
     "shell.execute_reply": "2026-01-31T06:45:13.232898Z",
     "shell.execute_reply.started": "2026-01-31T06:44:51.676160Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. Uninstall existing version to avoid conflicts\n",
    "!pip uninstall -y diffusers\n",
    "\n",
    "# 2. Install the latest \"dev\" version from source\n",
    "!pip install git+https://github.com/huggingface/diffusers\n",
    "\n",
    "# 3. Ensure other dependencies are up to date for SSD-1B\n",
    "!pip install -U -q accelerate transformers peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T06:31:07.640836Z",
     "iopub.status.busy": "2026-01-31T06:31:07.640406Z",
     "iopub.status.idle": "2026-01-31T06:31:35.116948Z",
     "shell.execute_reply": "2026-01-31T06:31:35.116312Z",
     "shell.execute_reply.started": "2026-01-31T06:31:07.640801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# 1. PASTE YOUR COPIED CSV PATH HERE:\n",
    "CSV_PATH = \"/kaggle/input/labels/demo.csv\" \n",
    "\n",
    "IMG_SOURCE_DIR = \"/kaggle/input/pixel-art/images/images\"\n",
    "TRAIN_DIR = \"/kaggle/working/train_data\"\n",
    "LIMIT = 3000 # Your project requirement\n",
    "MANDATORY_KEYWORDS = \"pixel art, 16-bit, sprite, \"\n",
    "\n",
    "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df_sample = df.sample(n=min(LIMIT, len(df)), random_state=42)\n",
    "\n",
    "metadata = []\n",
    "print(f\"Moving {len(df_sample)} images to training folder...\")\n",
    "\n",
    "for index, row in tqdm(df_sample.iterrows(), total=len(df_sample)):\n",
    "    file_name = row['file_name']\n",
    "    caption = row['text']\n",
    "    \n",
    "    source_path = os.path.join(IMG_SOURCE_DIR, file_name)\n",
    "    target_path = os.path.join(TRAIN_DIR, file_name)\n",
    "    \n",
    "    if os.path.exists(source_path):\n",
    "        shutil.copy(source_path, target_path)\n",
    "        # Combine your mandatory style keywords with the CSV caption\n",
    "        # full_caption = MANDATORY_KEYWORDS + str(caption)\n",
    "        full_caption = str(caption)\n",
    "        metadata.append({\"file_name\": file_name, \"text\": full_caption})\n",
    "\n",
    "# Save the metadata file that the training script expects\n",
    "with open(os.path.join(TRAIN_DIR, \"metadata.jsonl\"), 'w') as f:\n",
    "    for entry in metadata:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(f\"Successfully prepared {len(metadata)} images in {TRAIN_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T07:44:21.536180Z",
     "iopub.status.busy": "2026-01-31T07:44:21.535648Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!accelerate launch --num_processes=1 train_text_to_image_lora_sdxl.py \\\n",
    "  --pretrained_model_name_or_path=\"segmind/SSD-1B\" \\\n",
    "  --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" \\\n",
    "  --train_data_dir=\"/kaggle/working/train_data\" \\\n",
    "  --caption_column=\"text\" \\\n",
    "  --resolution=512 \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=8 \\\n",
    "  --learning_rate=5e-5 \\\n",
    "  --rank=16 \\\n",
    "  --max_train_steps=2000 \\\n",
    "  --checkpointing_steps=500 \\\n",
    "  --validation_prompt=\"16x16 pixel art of a small owl flying\" \\\n",
    "  --validation_epochs=1 \\\n",
    "  --num_validation_images=4 \\\n",
    "  --output_dir=\"/kaggle/working/court_of_owls_lora\" \\\n",
    "  --seed=42 \\\n",
    "  --report_to=\"tensorboard\" \\\n",
    "  --dataloader_num_workers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T13:08:03.022574Z",
     "iopub.status.busy": "2026-01-31T13:08:03.022247Z",
     "iopub.status.idle": "2026-01-31T13:08:03.031440Z",
     "shell.execute_reply": "2026-01-31T13:08:03.030833Z",
     "shell.execute_reply.started": "2026-01-31T13:08:03.022545Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No validation images generated yet. Wait for step 500!\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "# import glob\n",
    "# import os\n",
    "\n",
    "# # Check multiple possible locations for validation images\n",
    "# possible_paths = [\n",
    "#     '/kaggle/working/court_of_owls_lora/samples/*.png',\n",
    "#     '/kaggle/working/court_of_owls_lora/*.png',\n",
    "#     '/kaggle/working/court_of_owls_lora/**/*.png'\n",
    "# ]\n",
    "\n",
    "# sample_images = []\n",
    "# for path in possible_paths:\n",
    "#     sample_images.extend(glob.glob(path, recursive=True))\n",
    "\n",
    "# sample_images = list(set(sample_images))  # Remove duplicates\n",
    "# sample_images.sort(key=os.path.getmtime)\n",
    "\n",
    "# if sample_images:\n",
    "#     # Show the last 4 validation images\n",
    "#     num_to_show = min(4, len(sample_images))\n",
    "#     fig, axes = plt.subplots(1, num_to_show, figsize=(5*num_to_show, 5))\n",
    "#     if num_to_show == 1:\n",
    "#         axes = [axes]\n",
    "    \n",
    "#     for ax, img_path in zip(axes, sample_images[-num_to_show:]):\n",
    "#         img = Image.open(img_path)\n",
    "#         ax.imshow(img)\n",
    "#         ax.axis('off')\n",
    "#         ax.set_title(os.path.basename(img_path))\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "# else:\n",
    "#     print(\"No validation images found yet.\")\n",
    "#     print(\"Check output directory contents:\")\n",
    "#     !ls -la /kaggle/working/court_of_owls_lora/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 15527960,
     "datasetId": 9381101,
     "sourceId": 14684698,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 7695834,
     "datasetId": 4424547,
     "sourceId": 7600561,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
