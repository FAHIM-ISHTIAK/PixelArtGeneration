{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":14684698,"datasetId":9381101,"databundleVersionId":15527960},{"sourceType":"datasetVersion","sourceId":7600561,"datasetId":4424547,"databundleVersionId":7695834}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install the necessary libraries\n!pip install -U -q diffusers accelerate transformers peft bitsandbytes\n!pip install -q wandb # For metric identification and tracking\n\n# Download the official training script for SDXL/SSD-1B\n!wget https://raw.githubusercontent.com/huggingface/diffusers/main/examples/text_to_image/train_text_to_image_lora_sdxl.py","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-31T08:14:06.544909Z","iopub.execute_input":"2026-01-31T08:14:06.545141Z","iopub.status.idle":"2026-01-31T08:14:09.821219Z","shell.execute_reply.started":"2026-01-31T08:14:06.545116Z","shell.execute_reply":"2026-01-31T08:14:09.820552Z"}},"outputs":[{"name":"stdout","text":"^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m--2026-01-31 08:14:09--  https://raw.githubusercontent.com/huggingface/diffusers/main/examples/text_to_image/train_text_to_image_lora_sdxl.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 56285 (55K) [text/plain]\nSaving to: ‘train_text_to_image_lora_sdxl.py.2’\n\ntrain_text_to_image 100%[===================>]  54.97K  --.-KB/s    in 0.01s   \n\n2026-01-31 08:14:09 (4.63 MB/s) - ‘train_text_to_image_lora_sdxl.py.2’ saved [56285/56285]\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# 1. Uninstall existing version to avoid conflicts\n!pip uninstall -y diffusers\n\n# 2. Install the latest \"dev\" version from source\n!pip install git+https://github.com/huggingface/diffusers\n\n# 3. Ensure other dependencies are up to date for SSD-1B\n!pip install -U -q accelerate transformers peft bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T06:44:51.675287Z","iopub.execute_input":"2026-01-31T06:44:51.676199Z","iopub.status.idle":"2026-01-31T06:45:13.233696Z","shell.execute_reply.started":"2026-01-31T06:44:51.676160Z","shell.execute_reply":"2026-01-31T06:45:13.232898Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport shutil\nimport json\nfrom tqdm import tqdm\n\n# --- CONFIGURATION ---\n# 1. PASTE YOUR COPIED CSV PATH HERE:\nCSV_PATH = \"/kaggle/input/labels/demo.csv\" \n\nIMG_SOURCE_DIR = \"/kaggle/input/pixel-art/images/images\"\nTRAIN_DIR = \"/kaggle/working/train_data\"\nLIMIT = 3000 # Your project requirement\nMANDATORY_KEYWORDS = \"pixel art, 16-bit, sprite, \"\n\nos.makedirs(TRAIN_DIR, exist_ok=True)\n\n# Load the CSV\ndf = pd.read_csv(CSV_PATH)\ndf_sample = df.sample(n=min(LIMIT, len(df)), random_state=42)\n\nmetadata = []\nprint(f\"Moving {len(df_sample)} images to training folder...\")\n\nfor index, row in tqdm(df_sample.iterrows(), total=len(df_sample)):\n    file_name = row['file_name']\n    caption = row['text']\n    \n    source_path = os.path.join(IMG_SOURCE_DIR, file_name)\n    target_path = os.path.join(TRAIN_DIR, file_name)\n    \n    if os.path.exists(source_path):\n        shutil.copy(source_path, target_path)\n        # Combine your mandatory style keywords with the CSV caption\n        # full_caption = MANDATORY_KEYWORDS + str(caption)\n        full_caption = str(caption)\n        metadata.append({\"file_name\": file_name, \"text\": full_caption})\n\n# Save the metadata file that the training script expects\nwith open(os.path.join(TRAIN_DIR, \"metadata.jsonl\"), 'w') as f:\n    for entry in metadata:\n        f.write(json.dumps(entry) + \"\\n\")\n\nprint(f\"Successfully prepared {len(metadata)} images in {TRAIN_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T06:31:07.640406Z","iopub.execute_input":"2026-01-31T06:31:07.640836Z","iopub.status.idle":"2026-01-31T06:31:35.116948Z","shell.execute_reply.started":"2026-01-31T06:31:07.640801Z","shell.execute_reply":"2026-01-31T06:31:35.116312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!accelerate launch --num_processes=1 train_text_to_image_lora_sdxl.py \\\n  --pretrained_model_name_or_path=\"segmind/SSD-1B\" \\\n  --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" \\\n  --train_data_dir=\"/kaggle/working/train_data\" \\\n  --caption_column=\"text\" \\\n  --resolution=1024 \\\n  --mixed_precision=\"fp16\" \\\n  --train_batch_size=1 \\\n  --gradient_accumulation_steps=4 \\\n  --learning_rate=1e-4 \\\n  --rank=4 \\\n  --max_train_steps=1500 \\\n  --checkpointing_steps=100 \\\n  --validation_prompt=\"16x16 pixel art of a small owl flying\" \\\n  --output_dir=\"/kaggle/working/court_of_owls_lora\" \\\n  --seed=42 \\\n  --report_to=\"tensorboard\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T07:44:21.535648Z","iopub.execute_input":"2026-01-31T07:44:21.536180Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\nimport glob\nimport os\n\n# This looks for the most recent validation images\nsample_images = glob.glob('/kaggle/working/court_of_owls_lora/samples/*.png')\nsample_images.sort(key=os.path.getmtime) # Sort by newest first\n\nif sample_images:\n    latest_img = sample_images[-1]\n    print(f\"Showing latest validation: {latest_img}\")\n    img = Image.open(latest_img)\n    plt.figure(figsize=(10, 10))\n    plt.imshow(img)\n    plt.axis('off')\n    plt.show()\nelse:\n    print(\"No validation images generated yet. Wait for step 500!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T13:08:03.022247Z","iopub.execute_input":"2026-01-31T13:08:03.022574Z","iopub.status.idle":"2026-01-31T13:08:03.031440Z","shell.execute_reply.started":"2026-01-31T13:08:03.022545Z","shell.execute_reply":"2026-01-31T13:08:03.030833Z"}},"outputs":[{"name":"stdout","text":"No validation images generated yet. Wait for step 500!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}